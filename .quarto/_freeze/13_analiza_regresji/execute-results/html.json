{
  "hash": "0e71a0d2521c530fe1436842182e49c7",
  "result": {
    "markdown": "# Analiza regresji\n\nGłówną ideą regresji jest wyjaśnianie, przewidywanie, prognozowanie danych dla pewnej zmiennej (określanej jako zmienna zależna, objaśniana, wyjaśniana) na podstawie innych zmiennych (zmienne niezależne, predyktory, zmienne objaśniające, zmienne wyjaśniające).\n\nBudowa liniowego modelu zależności między dwoma zmiennymi składa się z trzech etapów:\n\n1.  Określenie czy między zmiennymi istnieje zależność.\n\n    -   wykonanie wykresu rozrzutu\n    -   współczynnik korelacji\n\n2.  Budowa modelu.\n\n3.  Analiza wyników modelu (w tym ocena dopasowania modelu).\n\nPo zbudowaniu modelu oraz ocenie dopasowania modelu można go wykorzystać do wykonania **predykcji**.\n\n## Podstawowe pojęcia\n\n-   **Analiza regresji** tworzy funkcję matematyczną opisującą zależność pomiędzy badanymi zmiennymi: zmienną zależną, którą chcemy przewidywać na podstawie zmiennych niezależnych.\n\n-   **Zmienna zależna** (inaczej *zmiena objaśniana, zmienna wyjaśniana, zmienna przewidywana*) - zmienna, której wartość chcemy przewidywać na podstawie modelu. W modelu może być tylko jedna zmienna zależna.\n\n-   **Zmienne niezależne** (inaczej *predyktory, zmienne objaśniające, zmienne wyjaśniające*) - zmienne używane w modelu do oszacowania wartości zmiennej zależnej. W modelu może być wiele zmiennych niezależnych.\n\n-   **Model regresyjny** - model, który będzie z założonym błędem statystycznym przewidywał wartość, poziom danej cechy.\n\n    -   W praktyce zawsze występuje pewna wielkość błędu oszacowania. Ideą regresji jest zminimalizowanie tego błędu oszacowania do tego stopnia, aby model był przydatny w swoich prognozach\n    -   Model regresyjny możemy zawsze zbudować, jednakże tylko te modele będą \"wartościowe\", w których błąd oszacowania będzie relatywnie niski.\n\n-   **Model regresji liniowej** to model, który zakłada liniową zależność między zmienną zależną a zmienną niezależną. Pozwala on na przewidywanie wartości zmiennej zależnej na podstawie wartości zmiennej niezależnej.\n\n-   **Metoda najmniejszych kwadratów błędów** - metoda, która ma na celu dopasowanie do zebranych danych, takiej lini (dla regresji liniowej), która jest do nich najlepiej dopasowana - tzn. dla której suma kwadratów błędów będzie najniższa.\n\n## Regresja liniowa\n\n-   Najprostszym wariantem regresji jest regresja liniowa.\n-   W regresji liniowej zakłada się, że zależność pomiędzy zmienną objaśnianą ($y$), a objaśniająca ($x$) jest zależnością liniową.\n-   W regresji liniowej zakłada się, że wzrostowi jednej zmiennej (zmienna objaśniająca) towarzyszy wzrost lub spadek drugiej zmiennej.\n\nRegresja liniowa opisywana jest wzorem:\n\n$$y_i = \\alpha + \\beta x_i + \\varepsilon_i$$\n\n- $y$ - zmienna zależna (zmienna wyjaśniana, przewidywana) \n- $\\alpha$ - wyraz wolny \n- $\\beta$ - współczynnik kierunkowy dla zmiennej $x$ (mówiący o nachyleniu prostej regresji) \n- $x$ - zmienna niezależna (predyktor, zmienna wyjaśniająca) \n- $\\varepsilon$ - błąd losowy\n\nRównanie to opisuje oczekiwaną średnią wartość zmiennej $y$ jako liniowej kombinacji zmiennej (lub zmiennych) $x$.\n\n## Metoda najmniejszych kwadratów\n\n-   Wyznaczenie modelu regresji liniowej (linii regresji) sprowadza się do obliczenia współczynników linii prostej (współczynników regresji: $\\beta$ oraz $\\alpha$ (wyraz wolny)). W tym celu wykorzystuje się **metodę najmniejszych kwadratów błędu** (nazywaną też metodą najmniejszych kwadratów).\n\n-   Metoda najmniejszych kwadratów jest jedną z najważniejszych i najstarszych metod obliczeniowych w statystyce.\n\n-   Metoda ta ma na celu dopasowanie do zebranych danych, takiej linii prostej (model liniowy), która jest do nich najlepiej dopasowana - tzn. dla której suma kwadratów błędów będzie najniższa.\n\n    -   Metoda dopasowuje taką linię do zebranych danych, aby ogólny błąd oszacowania (dla wszystkich danych) był jak najmniejszy.\n\n-   Metoda najmniejszych kwadratów nie jest odporna na wartości odstające w zbiorze danych. Powodem tego jest fakt, że wartość odstająca \"pociąga\" za sobą linię regresji. Gdyby nie było wartości odstającej linia byłaby inna, zdecydowanie lepiej dopasowana do wszystkich innych obserwacji, a tak wartość odstająca zmienia kierunek linii i powoduje, że model traci swoją \"moc przewidywania\" dla pozostałych obserwacji.\n\n![](figures/12_metoda_kwadraty.png){width=\"550\"}\n\n**Interaktywna wizualizacja regresji liniowej**\n\n-   [https://observablehq.com/\\@yizhe-ang/interactive-visualization-of-linear-regression](https://observablehq.com/@yizhe-ang/interactive-visualization-of-linear-regression)\n\n## Predykcja\n\n-   Znając wzór modelu regresji (znając współczynniki modelu) możemy oszacować wartości zmiennej zależnej (zmiennej objaśnianej, $y$) na podstawie wartości predyktora (zmienna objaśniająca, $x$) podstawiając odpowiednią wartość $x$ do uzyskanego wzoru. Dlatego też mówimy, że analiza regresji służy do przewidywania wartości jednej zmiennej na podstawie innych.\n\n## Analiza regresji liniowej w R \n\n### Formuły w R \n\nW R równanie modelu regresji opisywane jest za pomoca tzw. __FORMUŁY__\n\n- Formuła to symboliczny opis zależności między zmiennymi \n- Wykorzystywana jest przez różne funkcje w R (np. `lm()`, `aggregate()`) oraz wykresy.\n- Ogólna postać to: ***LewaStrona ~ PrawaStrona*** \n\n    + lewa strona formuły najczęściej składa się z jednej zmiennej, prawa strona formuły może składać się z jednej lub kilku zmiennych. \n\n- w równaniach regresji formuła ma postać: zmiennaObjaśniana ~ zmiennaObjaśniajaca\n\nJeśli zmiennych objaśniających jest więcej to rozdziela się je znakiem + \n\nzmiennaObjaśniana ~ zm1 + zm2 ... + zmN\n\n**Przykład**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny ~ x #czytamy y zależy od x \n```\n:::\n\n\n**Kilka uwag o konstruowaniu formuł w R:**\n\n- nazwy zmiennych pojawiające się w formułach powinny być widoczne w środowisku R lub być nazwami kolumn ramki danych\n\n- znak - (minus) przed zmienną oznacza usunięcie zmiennej z formuły \n\n- $-1$ oznacza usunięcie z formuły wyrazu wolnego, to samo otrzymamy dodając do formuły \"+0\"\n\n- $+1$ - oznacza dodanie do formuły wyrazu wolnego\n\n- w formułach można wykorzystywać funkcje matematyczne i inne funkcje programu R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny ~ log(x)\nlog(y) ~ x\n```\n:::\n\n\n- Jeśli w formule chcemy użyć znaku $+$ jako arytmetycznego działania musimy użyć funkcji `I()`. Argumenty tej funkcji traktowane są jako działania artymetyczne a nie elementy formuły. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ny ~ a + b # y zależy od a oraz od b \ny ~ I(a + b) # y zależy od wyniku dodawania wartości a do b \n```\n:::\n\n\n- '.' (krokpa) oznacza że badamy zależnośc y od wszystkich innych zmiennych\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny ~. # y od wszyatkich pozostałych zmiennych \ny ~. -1  # y od wszyatkich pozostałych zmiennych bez wyrazu wolnego \n```\n:::\n\n\n- zastosowanie formuł, gdy zmienne są kolumnami ramki danych \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#obliczenie średniej wartości zmiennej x względem grup g dla danych zawartych w ramce danych df\naggregate(x~g, data = df, FUN = mean)\n\n#skonstruowanie modelu liniowego zależności zmiennej y od wszystkich pozostałych zmiennych w ramce danych df\nlm(y ~ ., data = df)\n```\n:::\n\n\n### Funkcja `lm()`\nW R do budowy modelu liniowego służy funkcja `lm()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(formula, data, subset, weights, na.action,\n   method = \"qr\", model = TRUE, x = FALSE, y = FALSE, qr = TRUE,\n   singular.ok = TRUE, contrasts = NULL, offset, ...)\n```\n:::\n\n\nWpisz `?lm` aby sprawdzić co oznaczają poszczególne elementy funkcji `lm()`\n\n## Przykład: Zależność między sumą opadów a maksymalną temperaturą powietrza we wrześniu. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npomiary_pol = read.csv(\"data/pomiary_pol.csv\")\npomiary_wlkp = subset(pomiary_pol, wojewodztwo == \"wielkopolskie\")\nhead(pomiary_wlkp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   pomiar_id   tmin_4   tmax_4   tmin_9   tmax_9 annual_tavg annual_precip\n11        11 3.335094 13.62580 9.084752 19.08217    8.384752      523.2002\n19        19 3.410387 12.50000 9.100000 17.57093    7.194528      616.3997\n28        28 3.500000 13.70000 9.152218 19.05079    8.348457      533.9985\n40        40 3.316587 13.11659 8.929418 18.22806    8.058362      542.9643\n43        43 3.600000 13.83129 9.200000 19.10000    8.331804      513.3343\n55        55 3.474023 12.50000 8.813623 17.31023    7.352345      613.1104\n   prow_id woj_id              prowincja   wojewodztwo\n11       4     15 Niż Środkowoeuropejski wielkopolskie\n19       4     15 Niż Środkowoeuropejski wielkopolskie\n28       4     15 Niż Środkowoeuropejski wielkopolskie\n40       4     15 Niż Środkowoeuropejski wielkopolskie\n43       4     15 Niż Środkowoeuropejski wielkopolskie\n55       4     15 Niż Środkowoeuropejski wielkopolskie\n```\n:::\n:::\n\n\n### Określenie zależności między sumą opadów, a maksymalną temperaturą powietrza we wrześniu\n\nUwaga! Zmienną zależną zawsze zaznaczamy na osi $y$, a zmienną niezależną na osi $x$. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nggplot(pomiary_wlkp, aes(x = tmax_9, y = annual_precip)) + \n  geom_point() + \n  labs(x = \"Temperatura września [C]\", y = \"Suma opadów [mm]\") + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](13_analiza_regresji_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(x = pomiary_wlkp$tmax_9, y = pomiary_wlkp$annual_precip, use = \"complete.obs\", method = \"pearson\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.8619021\n```\n:::\n:::\n\n\n> Jaka jest zależność między sumą opadów, a temperaturą maksymalną we wrześniu? \n\n## Budowa modelu\n\nW R do budowy modelu liniowego służy funkcja `lm()`. Do obowiązkowych argumentów funkcji należą: \n\n- *formula* - opisuje równanie modelu liniowego \n- *data* - wskazuje zbiór danych, zawierający dane wejściowe -zmienne objaśniające.  \n    \n\nFunkcja `lm()` dopasowuje model liniowy, wyznacza oceny współczynników $\\beta$ oraz wylicza wartości reszt. Wynikiem działania funkcji jest obiekt klasy *lm*, który będzie przechowywał informacje o dopasowanym modelu. \n\n**Model zależności między sumą opadów, a maksymalną temperaturą powietrza we wrześniu**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm1 = lm(annual_precip ~ tmax_9, data = pomiary_wlkp)\n```\n:::\n\n\n### Wyniki modelu \n\nFunkcja `lm()` dopasowuje model liniowy, wyznacza oceny współczynników $\\beta$ oraz wylicza wartości reszt. Wynikiem działania funkcji jest obiekt klasy *lm*, który będzie przechowywał informacje o dopasowanym modelu. Do ważniejszych informacji należą:\n\n- *coefficients* - wartości dopasowanych  współczynników modelu \n- *residuals* - wektor reszt (różnica dla wartości obserwowanej i oszacowanej przez model)\n- *fitted.values* - wektor ocen modelu \t\n- *call* - formuła użyta do budowy modelu\n- *model* - ramka danych użyta do budowy modelu\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(model_lm) \n```\n:::\n\n\n#### Współczynniki modelu \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = annual_precip ~ tmax_9, data = pomiary_wlkp)\n\nCoefficients:\n(Intercept)       tmax_9  \n    1357.90       -43.75  \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlm1$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)      tmax_9 \n 1357.89973   -43.74883 \n```\n:::\n:::\n\n\nW wyniku modelu otrzymamy wartości dwóch współczynników regresji:\n\n- współczynnika mówiącego o nachyleniu prostej regresji (tzw. współczynnik kierunkowy $\\beta$ - określa o ile jednostek przeciętnie wzrośnie (lub zmaleje gdy współczynnik ten ma wartość ujemną) wartość zmiennej zależnej (objaśnianej, przewidywanej), gdy wartość zmiennej niezależnej (objaśniającej, predyktorów) wzrośnie o jedną jednostkę.\n\n- wyraz wolny - Intercept ($\\alpha$)\n\nPodstawiając współczynniki do równania regresji liniowej \n\n$$y_i = \\alpha + \\beta x_i + \\varepsilon_i$$\notrzymamy\n\n$$y_i = 1357.90 + (-43.75)x_i + \\varepsilon_i$$\n### Podsumowanie wyników z modelu \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = annual_precip ~ tmax_9, data = pomiary_wlkp)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-22.340 -10.282  -2.329   9.170  69.844 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1357.90      41.89   32.41   <2e-16 ***\ntmax_9        -43.75       2.24  -19.53   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.45 on 132 degrees of freedom\nMultiple R-squared:  0.7429,\tAdjusted R-squared:  0.7409 \nF-statistic: 381.4 on 1 and 132 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\nPodsumowanie wyników modelu regresji składa się z kilku elementów:\n\n- formuły użytej do budowy modelu (*Call*)\n- statystyk reszt (*Residuals*) - reszty wyznacza się jako różnicę wartości obserwowanej oraz wartości oszacowanej z modelu.\n- współczynników modelu (*Coefficients*)\n- wyników mających na celu ocenę jakości uzyskanego modelu (*Residual standard error, Multiple R-square, Adjusted R-squared*)\n\n- **formuła użyta do budowy modelu (*Call*)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm1$call\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlm(formula = annual_precip ~ tmax_9, data = pomiary_wlkp)\n```\n:::\n:::\n\n\n- **statystyki reszt (*Residuals*)**\n\nDo oceny poprawności dopasowania modelu wykorzystuje się reszty (tzw.*residua*). Reszty wyznacza się jako różnicę wartości obserwowanej $y$ a wartości oszacowanej z modelu $\\hat{y}$ .\n\n$reszta = y - \\hat{y}$\n\n- $reszty > 0$ -> $y > \\hat{y}$ - wartość obserwowana ($y$) jest większa od wartości wyliczonej z modelu \\hat{y}\n\n- $reszty < 0$ -> $y < \\hat{y}$ - wartość obserwowana ($y$) jest mniejsza od wartości wyliczonej z modelu \\hat{y}\n\n- Statystyki reszt: Min - minimum, 1Q - pierwszy kwartyl, Median - mediana, 3Q - trzeci kwartyl, Max - maksimum.\n\n    + Duże odchylenia mediany od 0 mogą świadczyć o zależności nieliniowej.\n    + Średnia wartość błędu powinna być równa 0 - oznacza to, że błędy dodatnie i ujemne się równoważą\n\nInterpetacja wyników: \n\n- 50% odchyleń mieści się w zakresie -10.28 do 9.170 mm\n- mediana ma wartość -2.32, jest to niewielkie odchylenie biorąc pod uwagę zakres zmiennej *annual_precip* (509.5-631.2mm)\n\n\n- **Współczynniki** \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsmr = summary(lm1)\nsmr$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Estimate Std. Error   t value     Pr(>|t|)\n(Intercept) 1357.89973  41.893338  32.41326 1.038079e-64\ntmax_9       -43.74883   2.240235 -19.52868 9.413732e-41\n```\n:::\n:::\n\n\n\nTabela współczynniki zawiera następujące informacje dla każdego współczynnika:\n\n- *Estimate* - oceny wartości współczynników równania regresji  \n- *Std.Error* - błąd standardowy współczynnika (wartość 1 odchylenia standardowego; dla rozkładu normalnego w przedziale $średnia \\pm 1$ odchylenie standardowe mieści się 66% wartości danych)\n- *t-value* – wartość statystyki t \n- *p-value* – poziom istotności dla współczynnika\n\nInterpretacja: \n\n- Błąd standardowy współczynnika wskazuje, że z 66% prawdopodobieństwem możemy stwierdzić, że wartość współczynnika wyrazu wolnego wynosi $1357.90 \\pm 41.90$  (tj. 1 błąd standardowy ) a współczynnika kierunkowego $-43.75 \\pm 2.24$\n- Oba współczynniki są bardzo wysoce istotne statystycznie. Innymi słowy prawdopodobieństwo, że wartość współczynnika jest przypadkowa wynosi 9.413732e-41 dla współczynnika kierunkowego oraz 1.038079e-64 dla współczynnika wyrazu wolnego, a zatem jest znikomo mała. \n\n\n\n- **Residual standard error (błąd standardowy reszt; standardowy błąd oceny)**\n\n- Wartość 1 odchylenia standardowego; dla rozkładu normalnego w przedziale $średnia \\pm 1$ odchylenie standardowe mieści się 66% wartości danych.  \n- Pokazuje o ile przeciętnie wartości empiryczne odchylają się od wartości teoretycznych (wynikających ze zbudowanego modelu)\n\n```\nResidual standard error: 13.45 on 132 degrees of freedom\n```\nZ 66% prawdopodobieństwem możemy stwierdzić, że wartość rzeczywista nie będzie się różnić od prognozowanej o więcej niż  $\\pm 13.45 mm$ \n\n\n- **Multiple R-Squared, Adjusted R-Squared**\n\n- Przy ocenie dopasowania modelu należy zwrócić uwagę na wartość R2 przedstawiającą procent wariancji wyjaśnionej przez model, tzn. *__jaki procent zmienności zmiennej zależnej (objaśnianej) jest uwarunkowany zmiennością zmiennej niezależnej (objaśniającej)__*. \n- Im wyższa wartość współczynnika R2 (maksymalnie to 1) tym lepsze dopasowanie modelu do danych. \n- Niestety również im więcej zmiennych w modelu tym wyższa jest wartość współczynnika R2. Aby uwzględnić  liczbę zmiennych w modelu stosuje się modyfikację współczynnika R2, tzw. Zmodyfikowany R2 (ang. Adjusted R2)\n\nZatem:\n74.29% zmienności zmiennej *annual_precip* (sumy opadów) jest wyjaśniona przez zmienność zmiennej *tmax_9* (maksymalna temperatura powietrza we wrześniu).\n\n```\nMultiple R-squared:  0.7429,\tAdjusted R-squared:  0.7409 \n```\n### p-value {-}\n\n– wartość poziomu istotności całego modelu \nModel jest wysoko istotny\n\n```\nF-statistic: 381.4 on 1 and 132 DF,  p-value: < 2.2e-16\n```\n\n### Informacje zawarte w obiekcie klasy lm\n\nStworzenie ramki danych zawierającej wyniki modelu \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#ramka danych zawierająca dane użyte do budowy modelu\nmodel_df <- lm1$model\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#reszty - różnica między warrtością obserwowaną Y a wartością oszacowaną z modelu Ŷ. \nmodel_df$reszty <- lm1$residuals\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#wartości oszacowane przez model\nmodel_df$fitted <-  lm1$fitted.values\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(model_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   annual_precip   tmax_9      reszty   fitted\n11      523.2002 19.08217   0.1232246 523.0770\n19      616.3997 17.57093  27.2078768 589.1918\n28      533.9985 19.05079   9.5485351 524.4500\n40      542.9643 18.22806 -17.4791391 560.4434\n43      513.3343 19.10000  -8.9626913 522.2970\n55      613.1104 17.31023  12.5128960 600.5975\n```\n:::\n:::\n\n## Wizualizacja wyników modelu \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom); library(ggplot2)\nlm1_df = augment(lm1, se_fit = TRUE)\nggplot(lm1_df, aes(tmax_9, annual_precip)) + \n    geom_ribbon(aes(ymin = .fitted - 1.96 * .se.fit, \n                    ymax = .fitted + 1.96 * .se.fit), alpha = 0.2) +\n    geom_line(aes(tmax_9, .fitted)) + geom_point() + theme_bw()\n```\n\n::: {.cell-output-display}\n![](13_analiza_regresji_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\nWykorzystując informacje zawarte w obiekcie lm można wykonać wykres rozrzutu wartości obserwowanych, względem wartości obliczonych z modelu lub też przeanalizować rozkład reszt. \n\n- Histogram reszt z modelu \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nggplot(model_df, aes(x = reszty)) + \n  geom_histogram() +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](13_analiza_regresji_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n- Wykres rozrzutu: wartości dopasowane vs. wartości obserwowane\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(model_df, aes(x = fitted, y = annual_precip)) + \n  geom_point() + \n  labs(x = \"wartości dopasowane\", y = \"wartości obserwowane\") + \n  xlim(500, 650) + ylim(500, 650) + \n  coord_fixed(ratio=1) + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](13_analiza_regresji_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n## Predykcja\n\nMając dopasowany model liniowy możemy zastosować go do predykcji wartości $y$ dla zadanych wartości $x$. W poniższym przykładzie zastosujemy model liniowy do predykcji wartości sum opadów w województwie wielkopolskim na podstawie wartości maksymalnej temperatury powietrza. \n\nObiekt `model_lm` zawiera liniowy model zależności pomiędzy  sum opadów, a maksymalną temperaturą powietrza. Równanie regresji ma postać: \n\n$$y_i = 1357.90 + (-43.75)x_i + \\varepsilon_i$$\n\nJeśli np. wartość $x_i$ wynosi 10, to używając powyższego równania możemy obliczyć $y_i$: \n\n$$y_i = 1357.90 - 43.75 \\times 10 + \\varepsilon_i = 920.4$$\nBiorąc pod uwagę błąd losowy ($\\varepsilon_i$) wartość $y$ dla obiektu $i$ wynosi 920.4. \n\nInnymi słowy: Model regresji liniowej dla maksymalnej wartości temperatury powietrza (tmax_9) równej 9C, przewiduje wartość sumy opadów równą 920.4 mm. \n\nPowyżsżą wartość możemy także obliczyć jako \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm1$coefficients[[1]] + lm1$coefficients[[2]] * 10\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 920.4114\n```\n:::\n:::\n\n\nDo wykonania predykcji w R służy funkcja `predict()`. W funkcji tej musimy podać 2 argumenty: 1) obiekt modelu; 2) zbiór danych zawierający zmienne zależne (objaśniające). Nazwy kolumn muszą być zgodne z nazwami zmiennych zależnych użytych do budowy modelu. \n\nPredykcja może także zostać wykonana dla wybranych wartości. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#new to data.frame zawierajaca zmienne niezależne (objasniajace)\nnew <- data.frame(tmax_9 = c(10))\np <- predict(lm1, new)\np\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n920.4114 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(lm1, newdata = data.frame(tmax_9 = seq(15, 25, 1)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1        2        3        4        5        6        7        8 \n701.6673 657.9184 614.1696 570.4208 526.6719 482.9231 439.1743 395.4254 \n       9       10       11 \n351.6766 307.9278 264.1789 \n```\n:::\n:::\n\n\n> Używając modelu lm1 wykonaj predykcję dla wartości tmax_9 równej 12, 15, 25 i 30 C. \n\n## Regresja wielokrotna\n\nW modelu regresji możemy mieć tylko jedną zmienną zależną i wiele zmiennych niezależnych. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm2 = lm(annual_precip ~ tmax_9 + tmin_9, data = pomiary_wlkp)\nsummary(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = annual_precip ~ tmax_9 + tmin_9, data = pomiary_wlkp)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-38.763  -7.425  -0.572   5.794  37.450 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 1270.330     35.994  35.293  < 2e-16 ***\ntmax_9       -50.751      2.029 -25.009  < 2e-16 ***\ntmin_9        23.758      2.934   8.097  3.4e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.03 on 131 degrees of freedom\nMultiple R-squared:  0.8286,\tAdjusted R-squared:  0.826 \nF-statistic: 316.7 on 2 and 131 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n> Używając wyników modelu lm2: 1) Sformułuj równanie regresji liniowej wielokrotnej; 2) W jakim stopniu model wyjaśnia zmienną zależną (annual_precip)? 3) Wykonaj predykcję dla wartości tmax_9 równych 10C i 20C oraz wartości tmin_9 równych 5C i 12C. \n\n\n## Porównanie modeli\n\nKryterium informacyjne AIC pozwala porównać modele liniowe (im niższa wartość, tym lepiej).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAIC(lm1, lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    df      AIC\nlm1  3 1080.862\nlm2  4 1028.490\n```\n:::\n:::\n",
    "supporting": [
      "13_analiza_regresji_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}